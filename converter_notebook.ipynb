{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Morphology exporter**\n",
    "\n",
    "Hi!\n",
    "\n",
    "This notebook aims to explain the SWC to NeuroML converter I made.\n",
    "If you have any questions regarding the conversion, please contact me at s.reissenweber12@gmail.com.\n",
    "\n",
    "The converter translates the points in the SWC file to NeuroML segments, and organizes them into unbranched segment groups based on their type.\n",
    "These segment groups are then included in main segment groups (e.g. axon_group, soma_group).\n",
    "\n",
    "The converter tries to keep as much of the provided information as possible. For instance, comments at the start of SWC files, which often contain useful information, are preserved as notes at the beginning of the generated NML document.\n",
    "\n",
    "The converter also checks for SWC files that would be invalid in NeuroML and stores the error message, any additional information and fixes made in a dictionary. This can be printed if desired. When an unsolvable error arises (meaning an invalid SWC file), the conversion will stop and an exception is raised.\n",
    "\n",
    "Good luck with understanding the code! :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports:\n",
    "import neuroml\n",
    "import neuroml.writers as writers\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_nml(path, output_dir=''):\n",
    "    '''\n",
    "    This function is the big function that calls all helper functions to construct the neuroml file.\n",
    "\n",
    "    Input: - path: filepath to SWC file (str)\n",
    "           - output_dir (optional): directory in which the neuroml file will be saved (str)\n",
    "\n",
    "    Returns: - name of the newly created neuroml file (str)\n",
    "             - errors: dict {error message: {occurences: int, extra_info: [str], fix: str}}\n",
    "    '''\n",
    "    \n",
    "    errors = {}\n",
    "    d, comments = open_and_split(path, errors)\n",
    "    filename = os.path.basename(path).split('.')[0]\n",
    "    filename = change_filename(filename, errors)\n",
    "    cell_ID = f\"{filename}_cell\"\n",
    "    nml_doc = neuroml.NeuroMLDocument(id=filename)\n",
    "    nml_cell = neuroml.Cell(id=cell_ID)\n",
    "\n",
    "    make_notes(comments, nml_cell)\n",
    "    n, children, type_seg, root = classify_types_branches_and_leafs(d, errors)\n",
    "    segmentGroups = find_segments(d, n)\n",
    "    nml_mor = process_segments(d, children, root, cell_ID, errors)\n",
    "    nml_cell = process_cables(segmentGroups, type_seg, nml_mor, nml_cell)\n",
    "    nml_cell = define_biophysical_properties(nml_cell, cell_ID)\n",
    "\n",
    "    nml_doc.cells.append(nml_cell)\n",
    "    \n",
    "    if output_dir:\n",
    "        nml_file = f'{output_dir}/{filename}_converted.cell.nml'\n",
    "    else:\n",
    "        nml_file = f'{filename}_converted.cell.nml'\n",
    "    writers.NeuroMLWriter.write(nml_doc, nml_file)\n",
    "\n",
    "    return nml_file.split('/')[-1], errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversionException(Exception):\n",
    "    '''\n",
    "    This is an exception class used to store the errors dictionary when an exception is raised (swc file invalid).\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, message, errors):\n",
    "        super().__init__(message)\n",
    "        self.errors = errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_error(errors, error_type, occurrence=1, extra_info=None, fix=None, stop=False):\n",
    "    '''\n",
    "    This function logs errors detected in the SWC file to a dictionary adds any additional information about the errors.\n",
    "\n",
    "    Input: - errors: dict {error message: {occurences: int, extra_info: [str], fix: str}}\n",
    "           - error_type: error message (str)\n",
    "           - occurence (optional): amount of occurences (int)\n",
    "           - extra_info (optional): extra information about the error (str)\n",
    "           - fix (optional): measure implemented to fix the error (str)\n",
    "           - stop (optional): should the conversion continue or not (bool)\n",
    "    \n",
    "    Returns: None\n",
    "    '''\n",
    "\n",
    "    # Check if error_type is related to unknown SWC types\n",
    "    if error_type.startswith(\"Unknown type detected\"):\n",
    "        type_id = error_type[23:]\n",
    "        if \"Unknown type detected\" not in errors:\n",
    "            errors[\"Unknown type detected\"] = {}\n",
    "\n",
    "        if type_id not in errors[\"Unknown type detected\"]:\n",
    "            errors[\"Unknown type detected\"][type_id] = {\n",
    "                \"occurrences\": 0,\n",
    "                \"fix\": None\n",
    "            }\n",
    "\n",
    "        errors[\"Unknown type detected\"][type_id][\"occurrences\"] += occurrence\n",
    "        if fix is not None:\n",
    "            errors[\"Unknown type detected\"][type_id][\"fix\"] = fix\n",
    "    else:\n",
    "        if error_type not in errors:\n",
    "            errors[error_type] = {\n",
    "                \"occurrences\": 0,\n",
    "                \"fix\": None\n",
    "            }\n",
    "\n",
    "        errors[error_type][\"occurrences\"] += occurrence\n",
    "        if extra_info is not None:\n",
    "            if \"extra_info\" not in errors[error_type]:\n",
    "                errors[error_type][\"extra_info\"] = [extra_info]\n",
    "            else:\n",
    "                errors[error_type][\"extra_info\"].append(extra_info)\n",
    "        if fix is not None:\n",
    "            errors[error_type][\"fix\"] = fix\n",
    "\n",
    "    if stop:\n",
    "        raise ConversionException(error_type, errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_split(path, errors):\n",
    "    '''\n",
    "    This function takes a (path to an) SWC file and creates a dictionary with necessary information to generate the neuroml file.\n",
    "    \n",
    "    Input: - path: filepath to SWC file (str)\n",
    "           - errors: dict {error message: {occurences: int, extra_info: [str], fix: str}}\n",
    "    \n",
    "    Returns: - d: dict {point (int): (type, x_coord, y_coord, z_coord, radius, parent)}\n",
    "             - comments: list of comments [comment (str)]\n",
    "    '''\n",
    "\n",
    "    d = {}\n",
    "    line_nr = 0\n",
    "    comments = []\n",
    "    no_par = [0, []]  # Used for checking amount of segments without parent\n",
    "    invalid_lines = []\n",
    "    soma_detected = False # Used for checking if any soma samples are present\n",
    "\n",
    "    with open(path, 'r+') as f:\n",
    "        for line in f:\n",
    "            line_nr += 1\n",
    "            if not line:\n",
    "                pass\n",
    "            elif line.startswith('#') or line.startswith(\"*\"):\n",
    "                comments.append(line[1:].strip())\n",
    "            else:\n",
    "                information = [elem for elem in line.strip().split(' ') if elem]\n",
    "                if not information:\n",
    "                    pass\n",
    "                else:\n",
    "                    if len(information) != 7:\n",
    "                        invalid_lines.append(line_nr)\n",
    "                    else:\n",
    "                        seg_ID = int(information[0]) - 1\n",
    "                        type_ID = int(information[1])\n",
    "                        x_coor = float(information[2])\n",
    "                        y_coor = float(information[3])\n",
    "                        z_coor = float(information[4])\n",
    "                        rad = float(information[5])\n",
    "                        par_ID = int(information[6]) - 1\n",
    "\n",
    "                        if par_ID > seg_ID:\n",
    "                            log_error(errors, \"Parent ID referred to before being defined. Loops might be present\", extra_info=f\"Point {seg_ID + 1}, parent {par_ID + 1}\", fix=\"No fixes. SWC file is invalid\", stop=True)\n",
    "\n",
    "                        if type_ID == 1:\n",
    "                            soma_detected = True\n",
    "\n",
    "                        if par_ID < 0:\n",
    "                            par_ID = -1\n",
    "                            no_par[0] += 1\n",
    "                            no_par[1].append(seg_ID + 1)\n",
    "\n",
    "                        d[seg_ID] = (type_ID, x_coor, y_coor, z_coor, rad, par_ID)\n",
    "        \n",
    "    # Check if there are invalid lines in the SWC file\n",
    "    if invalid_lines:\n",
    "        log_error(errors, \"Line in SWC file contains an invalid amount of columns (more or less than 7)\", occurrence=len(invalid_lines), extra_info=f\"Lines {', '.join(map(str, invalid_lines))}\", fix=\"Skipped these lines\")\n",
    "\n",
    "    # Check if cell has segments\n",
    "    if not d:\n",
    "        log_error(errors, \"SWC file does not contain any segments\", fix=\"No fixes. SWC file is invalid.\", stop=True)\n",
    "    \n",
    "    # Check if cell has more than one or zero segment(s) without a parent\n",
    "    if no_par[0] == 0:\n",
    "        log_error(errors, \"Zero segments without parent (root segments) detected\", fix=\"No fixes. SWC file is invalid.\", stop=True)\n",
    "    if no_par[0] > 1:\n",
    "        log_error(errors, \"More than one segment without parent (root segment) detected\", extra_info=f\"Points {', '.join(map(str, no_par[1]))}\", fix=\"No fixes. SWC file is invalid.\", stop=True)\n",
    "\n",
    "    # Check if cell contains soma samples\n",
    "    if not soma_detected:\n",
    "        log_error(errors, \"No soma segments detected\", fix=\"No fixes. NML file will be invalid.\")\n",
    "\n",
    "    return d, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_filename(filename, errors):\n",
    "    '''\n",
    "    This function is used to change the filename to conform to neuroml filename pattern restrictions.\n",
    "\n",
    "    Inputs: - filename: str\n",
    "            - errors: dict {error message: {occurences: int, extra_info: [str], fix: str}}\n",
    "    \n",
    "    Returns: new_name: new file name (str)\n",
    "    '''\n",
    "    \n",
    "    new_name = re.sub(r'[^a-zA-Z0-9_]', '_', filename)\n",
    "    if new_name[0].isdigit():\n",
    "        new_name = '_' + new_name\n",
    "    \n",
    "    if new_name != filename:\n",
    "        log_error(errors, \"Filename does not comply with neuroml filename pattern restrictions.\", fix=f\"Changed filename to {new_name}\")\n",
    "        \n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_notes(comments, nml_cell):\n",
    "    '''\n",
    "    This function creates the notes listed at the top of the neuroml file. It also includes the original comments listed in the SWC file.\n",
    "\n",
    "    Input: - comments: list of comments [comment (str)]\n",
    "           - nml_cell: neuroml cell object\n",
    "    \n",
    "    Returns: None\n",
    "    '''\n",
    "\n",
    "    nml_cell.notes = \"\\n\\n\" + '*' * 40 + \\\n",
    "                     \"\\nThis NeuroML file was converted from SWC to NeuroML format by Sietse Reissenweber's converter. \\\n",
    "                     \\nFor any questions regarding the conversion, you can email me at s.reissenweber12@gmail.com. \\\n",
    "                     \\nThe notes listed below are the notes that were originally contained in the SWC file.\\n\" \\\n",
    "                     + '*' * 40 + \"\\n\\n\"\n",
    "\n",
    "    nml_cell.notes += \"#\" * 40 + \"\\n\\n\"\n",
    "\n",
    "    for comment in comments:\n",
    "        nml_cell.notes += f'{comment}\\n'\n",
    "\n",
    "    nml_cell.notes += \"\\n\" + \"#\" * 40 + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_types_branches_and_leafs(d, errors):\n",
    "    '''\n",
    "    This function classifies the segments into different types, and determines the children of points.\n",
    "    \n",
    "    Input: - d: dict {point (int): (type, x_coord, y_coord, z_coord, radius, parent)}\n",
    "           - errors: dict {error message: {occurences: int, extra_info: [str], fix: str}}\n",
    "    \n",
    "    Returns: - n: dict {amount of children (int): [points]}\n",
    "             - children: dict {point (int): [children]}\n",
    "             - type_seg: dict {point (int): type morph. part (e.g. soma) (str)}\n",
    "             - root: point without parent (int)\n",
    "    '''\n",
    "\n",
    "    n = {0: [],\n",
    "         1: [],\n",
    "         2: []}\n",
    "    root = -float(\"Inf\")\n",
    "    children = {}\n",
    "    type_seg = {}\n",
    "    endpoints = []\n",
    "    internal_points = []\n",
    "\n",
    "    for point, info in d.items():\n",
    "        # Create dict n:\n",
    "        number_of_children = 0\n",
    "        for info2 in d.values():\n",
    "            if info2[5] == point:\n",
    "                number_of_children += 1\n",
    "        if number_of_children == 0:\n",
    "            n[0].append(point)\n",
    "        elif number_of_children == 1:\n",
    "            n[1].append(point)\n",
    "        else:\n",
    "            n[2].append(point)\n",
    "\n",
    "        # Check for 0.0 diameter:\n",
    "        if info[4] <= 0.0:\n",
    "            d[point] = info[:4] + (0.000001,) + (info[5],)\n",
    "            if point in n[0]:\n",
    "                endpoints.append(point)\n",
    "            else:\n",
    "                internal_points.append(point)\n",
    "\n",
    "        # Create dicts type_seg and types:\n",
    "        if info[0] == 1:\n",
    "            type_seg[point] = 'soma'\n",
    "        elif info[0] == 2:\n",
    "            type_seg[point] = 'axon'\n",
    "        elif info[0] == 3:\n",
    "            type_seg[point] = 'bas_dend'\n",
    "        elif info[0] == 4:\n",
    "            type_seg[point] = 'ap_dend'\n",
    "        else:  # Account for custom types\n",
    "            type_id = f'custom_{info[0]}'\n",
    "            type_seg[point] = type_id\n",
    "            log_error(errors, f\"Unknown type detected: {type_id}\", fix=f\"Added new type {type_id} and new group {type_id}_group\")\n",
    "\n",
    "        # Find root:\n",
    "        if info[5] == -1:\n",
    "            root = point\n",
    "            if type_seg[root] != 'soma':\n",
    "                log_error(errors, \"Spherical root segment does not belong to soma_group\", fix=\"No fixes. NML file will be invalid.\")\n",
    "\n",
    "        children[point] = []\n",
    "\n",
    "    # Check for endpoints with zero radius\n",
    "    if endpoints:\n",
    "        log_error(errors, \"Endpoint of zero radius detected\", occurrence=len(endpoints), extra_info=f\"Points {', '.join(map(str, endpoints))}\", fix=f\"Changed radius to small number {0.000001}\")\n",
    "    \n",
    "    # Check for internal points with zero radius\n",
    "    if internal_points:\n",
    "        log_error(errors, \"Internal point of zero radius detected\", occurrence=len(internal_points), extra_info=f\"Points {', '.join(map(str, internal_points))}\", fix=f\"Changed radius to small number {0.000001}\")\n",
    "\n",
    "    # Create dict children:\n",
    "    for point, info in d.items():\n",
    "        if point != root:\n",
    "            children[info[5]].append(point)\n",
    "\n",
    "    return n, children, type_seg, root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segments(d, n):\n",
    "    '''\n",
    "    This function organizes the segments into unbranched segment groups of the same type.\n",
    "    \n",
    "    Input: - d: dict {point (int): (type, x_coord, y_coord, z_coord, radius, parent)}\n",
    "           - n: dict {amount of children (int): [points]}\n",
    "\n",
    "    Returns: - segmentGroups: list with lists of segmentgroups [[points], [points], ...]\n",
    "    '''\n",
    "\n",
    "    segmentGroups = []\n",
    "    \n",
    "    # Processing from leaf points to branch points:\n",
    "    for leaf in n[0]:\n",
    "        toAdd = leaf\n",
    "        group_type = d[toAdd][0]\n",
    "        segGr = []\n",
    "        segmentFound = False\n",
    "\n",
    "        while segmentFound is False:\n",
    "            if toAdd == -1:\n",
    "                segmentFound = True\n",
    "            if toAdd in n[2]:  # Found a branch point\n",
    "                segmentFound = True\n",
    "            elif d[toAdd][0] != group_type:\n",
    "                segmentGroups.append(segGr)\n",
    "                segGr = []\n",
    "                segGr.append(toAdd)\n",
    "                group_type = d[toAdd][0]\n",
    "                toAdd = d[toAdd][5]\n",
    "            else:\n",
    "                segGr.append(toAdd)\n",
    "                toAdd = d[toAdd][5]\n",
    "\n",
    "        if segGr:\n",
    "            segmentGroups.append(segGr)\n",
    "    \n",
    "    # Processing from branch points to other branch points:\n",
    "    for branch in n[2]:\n",
    "        toAdd = branch\n",
    "        group_type = d[toAdd][0]\n",
    "        segGr = []\n",
    "        segmentFound = False\n",
    "\n",
    "        while segmentFound is False:\n",
    "            if toAdd == -1:\n",
    "                segmentFound = True\n",
    "            elif toAdd in n[2] and toAdd != branch:\n",
    "                segmentFound = True\n",
    "            elif d[toAdd][0] != group_type:\n",
    "                segmentGroups.append(segGr)\n",
    "                segGr = []\n",
    "                segGr.append(toAdd)\n",
    "                group_type = d[toAdd][0]\n",
    "                toAdd = d[toAdd][5]\n",
    "            else:\n",
    "                segGr.append(toAdd)\n",
    "                toAdd = d[toAdd][5]\n",
    "\n",
    "        if segGr:\n",
    "            segmentGroups.append(segGr)\n",
    "\n",
    "    return segmentGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segments(d, children, root, Cell_ID, errors):\n",
    "    '''\n",
    "    This function incorporates the segments into the neuroml morphology object.\n",
    "\n",
    "    Input: - d: dict {point (int): (type, x_coord, y_coord, z_coord, radius, parent)}\n",
    "           - children: dict {point (int): [children]} \n",
    "           - root: point without parent (int)\n",
    "           - cell_ID: unique ID of neuroml cell (str) \n",
    "           - errors: dict {error message: {occurences: int, extra_info: [str], fix: str}}\n",
    "\n",
    "    Returns: nml_mor: neuroml morphology object    \n",
    "    '''\n",
    "\n",
    "    nml_mor = neuroml.Morphology(id=f'{Cell_ID}_morphology')\n",
    "\n",
    "    available_points = [root]\n",
    "    processed = []\n",
    "    all_processed = False\n",
    "\n",
    "    while all_processed is False:\n",
    "        next_to_process = min(available_points)\n",
    "\n",
    "        if next_to_process == root:  # Set distal and proximal points to root point if root\n",
    "            Soma_Root = neuroml.Point3DWithDiam(x=str(d[next_to_process][1]),\n",
    "                                                y=str(d[next_to_process][2]),\n",
    "                                                z=str(d[next_to_process][3]),\n",
    "                                                diameter=str(d[next_to_process][4] * 2))\n",
    "            distalp = Soma_Root\n",
    "            proximalp = Soma_Root\n",
    "        else:\n",
    "            distalp = neuroml.Point3DWithDiam(x=str(d[next_to_process][1]),\n",
    "                                              y=str(d[next_to_process][2]),\n",
    "                                              z=str(d[next_to_process][3]),\n",
    "                                              diameter=str(d[next_to_process][4] * 2))\n",
    "            parent = d[next_to_process][5]\n",
    "            proximalp = neuroml.Point3DWithDiam(x=str(d[parent][1]),\n",
    "                                                y=str(d[parent][2]),\n",
    "                                                z=str(d[parent][3]),\n",
    "                                                diameter=str(d[parent][4] * 2))\n",
    "\n",
    "        parentID = d[next_to_process][5]\n",
    "        if parentID != -1:\n",
    "            # Only one segment may be spherical and must belong to the soma_group SegmentGroup:\n",
    "            coord_distal = (d[next_to_process][1], d[next_to_process][2], d[next_to_process][3])\n",
    "            coord_proximal = (d[parent][1], d[parent][2], d[parent][3])\n",
    "            if coord_distal == coord_proximal and d[next_to_process][4] == d[parent][4]:\n",
    "                log_error(errors, \"Two segments detected with same radius and coordinates\", extra_info=f\"Segments {next_to_process} and {parent}\", fix=\"No fix cause don't know what to change!!!!!\")\n",
    "            \n",
    "            segpar = neuroml.SegmentParent(segments=parentID)\n",
    "            thisSeg = neuroml.Segment(id=str(next_to_process),\n",
    "                                      name=f'Comp_{str(next_to_process)}',\n",
    "                                      distal=distalp,\n",
    "                                      parent=segpar)\n",
    "        else:\n",
    "            thisSeg = neuroml.Segment(id=str(next_to_process),\n",
    "                                      name=f'Comp_{str(next_to_process)}',\n",
    "                                      proximal=proximalp,\n",
    "                                      distal=distalp)\n",
    "\n",
    "        nml_mor.segments.append(thisSeg)\n",
    "        processed.append(next_to_process)\n",
    "\n",
    "        available_points.remove(next_to_process)\n",
    "        available_points += children[next_to_process]\n",
    "        if not available_points:\n",
    "            all_processed = True\n",
    "\n",
    "    return nml_mor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cables(segmentGroups, type_seg, nml_mor, nml_cell):\n",
    "    '''\n",
    "    This function incorporates the segment groups into the morphology object and adds them to bigger segment groups.\n",
    "    The morphology object is then added to the cell object.\n",
    "\n",
    "    Input: - segmentGroups: list with lists of segmentgroups [[point], [point], ...]\n",
    "           - type_seg: dict {point (int): type morph. part (e.g. soma) (str)}\n",
    "           - nml_mor: neuroml morphology object\n",
    "           - nml_cell: neuroml cell object\n",
    "    \n",
    "    Returns: nml_cell: neuroml cell object\n",
    "    '''\n",
    "\n",
    "    cables = []\n",
    "\n",
    "    # Create main segment groups\n",
    "    all_cables = neuroml.SegmentGroup(id='all')\n",
    "    soma_group = neuroml.SegmentGroup(id='soma_group', neuro_lex_id='SAO:1044911821')\n",
    "    axon_group = neuroml.SegmentGroup(id='axon_group', neuro_lex_id='SAO:1770195789')\n",
    "    dendrite_group = neuroml.SegmentGroup(id='dendrite_group', neuro_lex_id='SAO:1211023249')\n",
    "    basal_group = neuroml.SegmentGroup(id='basal_group', neuro_lex_id='SAO:1079900774')\n",
    "    apical_group = neuroml.SegmentGroup(id='apical_group', neuro_lex_id='SAO:273773228')\n",
    "\n",
    "    custom_groups = {}  # Dictionary to hold custom segment groups\n",
    "    counter = {}  # Dictionary to keep track of ids of groups\n",
    "\n",
    "    for segmentGroup in segmentGroups:\n",
    "        type_cable = type_seg[segmentGroup[0]]\n",
    "        if type_cable not in counter:\n",
    "            counter[type_cable] = 1\n",
    "        else:\n",
    "            counter[type_cable] += 1\n",
    "        cable_id = f'{type_cable}_{counter[type_cable]}'\n",
    "        this_cable = neuroml.SegmentGroup(id=cable_id, neuro_lex_id='SAO:864921383')\n",
    "\n",
    "        for segment in reversed(segmentGroup):\n",
    "            member = neuroml.Member(segments=segment)\n",
    "            this_cable.members.append(member)\n",
    "\n",
    "        cables.append(this_cable)\n",
    "        cable_include = neuroml.Include(segment_groups=cable_id)\n",
    "        all_cables.includes.append(cable_include)\n",
    "\n",
    "        if type_cable == 'soma':\n",
    "            soma_group.includes.append(cable_include)\n",
    "        elif type_cable == 'axon':\n",
    "            axon_group.includes.append(cable_include)\n",
    "        elif type_cable == 'bas_dend':\n",
    "            basal_group.includes.append(cable_include)\n",
    "            dendrite_group.includes.append(cable_include)\n",
    "        elif type_cable == 'ap_dend':\n",
    "            apical_group.includes.append(cable_include)\n",
    "            dendrite_group.includes.append(cable_include)\n",
    "        else:\n",
    "            custom_group_id = f'{type_cable}_group'\n",
    "            if custom_group_id not in custom_groups:\n",
    "                custom_group = neuroml.SegmentGroup(id=custom_group_id)\n",
    "                custom_groups[custom_group_id] = custom_group\n",
    "            custom_groups[custom_group_id].includes.append(cable_include)\n",
    "\n",
    "    # Append all cables and segment groups to morphology\n",
    "    for cable in cables:\n",
    "        nml_mor.segment_groups.append(cable)\n",
    "\n",
    "    for type in [all_cables, basal_group, apical_group, soma_group, axon_group, dendrite_group]:\n",
    "        if type.includes:\n",
    "            nml_mor.segment_groups.append(type)\n",
    "\n",
    "    for custom_group in custom_groups.values():\n",
    "        nml_mor.segment_groups.append(custom_group)\n",
    "\n",
    "    nml_cell.morphology = nml_mor\n",
    "\n",
    "    return nml_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_biophysical_properties(nml_cell, Cell_ID):\n",
    "    '''\n",
    "    This function defines some basic biophysical properties for the given cell.\n",
    "    \n",
    "    Input: - nml_cell: neuroml cell object\n",
    "           - Cell_ID: unique ID of neuroml cell (str) \n",
    "    \n",
    "    Returns: nml_cell: neuroml cell object\n",
    "    '''\n",
    "\n",
    "    # Create biophysical properties object\n",
    "    all_props = neuroml.BiophysicalProperties(id=f'{Cell_ID}_properties')\n",
    "\n",
    "    # Create and configure membrane properties\n",
    "    membrane_props = neuroml.MembraneProperties()\n",
    "    membrane_props.spike_threshes.append(neuroml.SpikeThresh(value='0.0 mV'))\n",
    "    membrane_props.specific_capacitances.append(neuroml.SpecificCapacitance(value='1.0 uF_per_cm2'))\n",
    "    membrane_props.init_memb_potentials.append(neuroml.InitMembPotential(value='-60.0 mV'))\n",
    "\n",
    "    # Create and configure intracellular properties\n",
    "    intra_props = neuroml.IntracellularProperties()\n",
    "    intra_props.resistivities.append(neuroml.Resistivity(value='0.03 kohm_cm'))\n",
    "\n",
    "    # Assign properties to the object\n",
    "    all_props.membrane_properties = membrane_props\n",
    "    all_props.intracellular_properties = intra_props\n",
    "\n",
    "    # Assign object to cell\n",
    "    nml_cell.biophysical_properties = all_props\n",
    "\n",
    "    return nml_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting a single file**\n",
    "\n",
    "In the second cell below, you can specify the file to be converted, as well as the output directory in which the converted file will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file(path, output_dir):\n",
    "    swc_file = os.path.basename(path)\n",
    "    try:\n",
    "        nml_file, errors = construct_nml(path, output_dir=output_dir)\n",
    "        print(f'Converted {swc_file} to the following file: {nml_file}')\n",
    "        print(json.dumps(errors, indent=2, separators=(',', ': ')))\n",
    "    except Exception as e:\n",
    "        print(f'Error converting {swc_file}: {e}')\n",
    "        print(json.dumps(e.errors, indent=2, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted BW022205nC-2.swc to the following file: BW022205nC_2_converted.cell.nml\n",
      "{\n",
      "  \"Filename does not comply with neuroml filename pattern restrictions.\": {\n",
      "    \"occurrences\": 1,\n",
      "    \"fix\": \"Changed filename to BW022205nC_2\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "path = \"swc_api\\BW022205nC-2.swc\"\n",
    "output_dir = 'mock_path'\n",
    "\n",
    "convert_file(path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting files from a directory**\n",
    "\n",
    "In the second cell below, you can specify the directory from which the swc files will be converted. Additionally, you can specify the output directory in which the converted file will be stored. The boolean print_errors will determine if the error dictionary is printed for every cell.\n",
    "\n",
    "A summary is printed, which is a dictionary containing the amount of (un)successful conversions and the amount of times certain errors occurred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_directory(path_swc, path_nml, print_errors):\n",
    "    summary = {}\n",
    "    summary['Successful conversions'] = 0\n",
    "    summary['Unsuccessful conversions'] = 0\n",
    "    summary['Errors'] = {}\n",
    "\n",
    "    # Use os.walk to iterate through all directories and subdirectories\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(path_swc):\n",
    "        for file in files:\n",
    "            if file.endswith('.swc'):\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        swc_file = os.path.basename(file_path)\n",
    "\n",
    "        try:\n",
    "            nml_file, errors = construct_nml(file_path, output_dir=path_nml)\n",
    "            summary['Successful conversions'] += 1\n",
    "            print(f'Converted {swc_file} to the following file: {nml_file}\\n')\n",
    "        except Exception as e:\n",
    "            errors = e.errors\n",
    "            summary['Unsuccessful conversions'] += 1\n",
    "            print(f'Error converting {swc_file}: {e}\\n')\n",
    "\n",
    "        if print_errors and errors:\n",
    "            print(json.dumps(errors, indent=2, separators=(',', ': ')))\n",
    "\n",
    "        for error in errors:\n",
    "            if error not in summary['Errors']:\n",
    "                summary['Errors'][error] = 1\n",
    "            else:\n",
    "                summary['Errors'][error] += 1\n",
    "\n",
    "    pprint.pprint(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['swc_no_api\\\\GGN_20170309_sc.swc', 'swc_no_api\\\\neuron_nmo\\\\cox\\\\CNG version\\\\cox-5-5_5.CNG.swc', 'swc_no_api\\\\neuron_nmo\\\\jacobs\\\\CNG version\\\\13-2-4.CNG.swc', 'swc_no_api\\\\neuron_nmo\\\\jan\\\\CNG version\\\\MAX_2015-06-05-animal7-A2-63x-uncut.CNG.swc', 'swc_no_api\\\\neuron_nmo\\\\johnson\\\\CNG version\\\\RetExp9-RGC2-D0.CNG.swc', 'swc_no_api\\\\neuron_nmo\\\\johnson_t\\\\CNG version\\\\RetExp9-RGC2-D0.CNG.swc', 'swc_no_api\\\\neuron_nmo\\\\luo\\\\CNG version\\\\02_NC_14.CNG.swc', 'swc_no_api\\\\neuron_nmo\\\\nacher\\\\CNG version\\\\A3N3.CNG.swc', 'swc_no_api\\\\neuron_nmo\\\\siegert\\\\CNG version\\\\CN_Development_P7_M_Animal03_Trace102.CNG.swc', 'swc_no_api\\\\neuron_nmo\\\\siegert\\\\CNG version\\\\DG_5xFAD_3mpos_F_Animal01_Trace102.CNG.swc', 'swc_no_api\\\\neuron_nmo\\\\wadiche\\\\CNG version\\\\T-3.CNG.swc', 'swc_no_api\\\\neuron_nmo\\\\yayon_soreq\\\\CNG version\\\\Cell_090_MPD_8_FT_10_XYZ_Sorted-swc_N3DFix-swc_1.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\althammer\\\\CNG version\\\\PVN14_microglia_11.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\baier\\\\CNG version\\\\161019_12_1.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\bellesi_zhang\\\\CNG version\\\\CSR2_water-4-SNT_Data-exported-016.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\bellesi_zhang\\\\CNG version\\\\CTR7_water-2-SNT_Data-exported-005.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\buffo\\\\CNG version\\\\1-1-1_6.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\chiang\\\\CNG version\\\\Gad1-F-200355.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\chiang\\\\CNG version\\\\VGlut-F-300031.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\chiang\\\\CNG version\\\\VGlut-F-400056.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\chiang\\\\CNG version\\\\VGlut-F-500070.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\chklovskii\\\\CNG version\\\\446263.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\ciganok-huckels_jehasse_kampa\\\\CNG version\\\\1626_S5_L2-000.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\coate\\\\CNG version\\\\20190417-6B-3_P11_2.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\defelipe\\\\CNG version\\\\J26_WTIV_n42_CA1_basal_cel1.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\defelipe\\\\CNG version\\\\V2KO_19.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\eyewire\\\\CNG version\\\\skel_20073_sorted.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\franca\\\\CNG version\\\\RatS1-6-59.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\gaspar\\\\CNG version\\\\1-CTR_2w_Female_HIP_10.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\gaspar\\\\CNG version\\\\6-STRESS_male_Nac_1.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\ginty\\\\CNG version\\\\Igbpf5-7866-03-F_1.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\hamad\\\\CNG version\\\\Culture-72-3.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\harland\\\\CNG version\\\\BAS4-2.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\hart\\\\CNG version\\\\2017-3-12_525_nrx1_day3_2.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\husttdi\\\\CNG version\\\\Neuron_Hust_16.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\jacobs\\\\CNG version\\\\196-4-13nj.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\khankan\\\\CNG version\\\\7B-09-traced-10.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\king\\\\CNG version\\\\B4-CA1-L-B63x1zCell2ACR.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\kuddannaya\\\\CNG version\\\\Tracetest_N360_circle_Map2Tau2_72_semi-auto_44.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\lambe\\\\CNG version\\\\C5---Adult-WT-Con.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\lee_cj\\\\CNG version\\\\210708-ipsi-03_38.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\mouselight\\\\CNG version\\\\AA1544.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\pandit_eswarappa\\\\CNG version\\\\1_tracing_10X_Neuro-2a_2-day-2_30.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\papageorgiou_kann\\\\CNG version\\\\CA1-cell-3_3.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\rodrigues\\\\CNG version\\\\218_1.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\roysam\\\\CNG version\\\\farsight3004.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\scott\\\\CNG version\\\\16149113.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\seo\\\\CNG version\\\\E4F-97_2_A.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\seo\\\\CNG version\\\\TE3F-78_1_D.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\siegert\\\\CNG version\\\\CB_5xFAD_6mpos_M_Animal01_Trace013.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\siegert\\\\CNG version\\\\CB_Adulthood_Control_M_Animal02_Trace019.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\siegert\\\\CNG version\\\\FC_CKp25_6w_F_Animal04_Trace159.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\siegert\\\\CNG version\\\\FC_Development_P15_M_Animal02_Trace024.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\siegert\\\\CNG version\\\\S1_Adulthood_Control_F_Animal10_Trace034.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\siegert\\\\CNG version\\\\S1_Recovery_2w_M_Animal02_Trace014.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\tensaouti\\\\CNG version\\\\3929-P6.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\urban_k\\\\CNG version\\\\B4_slide4_1.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\uusisaari\\\\CNG version\\\\21A_1a.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\vuksic\\\\CNG version\\\\ECL180_GrCellNr8_OML_IML.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\xiong\\\\CNG version\\\\TRN-4-CER-488-IBA1-594-2_1.CNG.swc', 'swc_no_api\\\\neuron_nmo_1\\\\zhang_x\\\\CNG version\\\\20121025cell05_1_a.CNG.swc', 'swc_no_api\\\\Thu Jun 13 2024 00_23_05 GMT+0200 (Midden-Europese zomertijd)\\\\T-3.CNG.swc']\n",
      "Converted GGN_20170309_sc.swc to the following file: GGN_20170309_sc_converted.cell.nml\n",
      "\n",
      "Converted cox-5-5_5.CNG.swc to the following file: cox_5_5_5_converted.cell.nml\n",
      "\n",
      "Converted 13-2-4.CNG.swc to the following file: _13_2_4_converted.cell.nml\n",
      "\n",
      "Converted MAX_2015-06-05-animal7-A2-63x-uncut.CNG.swc to the following file: MAX_2015_06_05_animal7_A2_63x_uncut_converted.cell.nml\n",
      "\n",
      "Converted RetExp9-RGC2-D0.CNG.swc to the following file: RetExp9_RGC2_D0_converted.cell.nml\n",
      "\n",
      "Converted RetExp9-RGC2-D0.CNG.swc to the following file: RetExp9_RGC2_D0_converted.cell.nml\n",
      "\n",
      "Converted 02_NC_14.CNG.swc to the following file: _02_NC_14_converted.cell.nml\n",
      "\n",
      "Converted A3N3.CNG.swc to the following file: A3N3_converted.cell.nml\n",
      "\n",
      "Converted CN_Development_P7_M_Animal03_Trace102.CNG.swc to the following file: CN_Development_P7_M_Animal03_Trace102_converted.cell.nml\n",
      "\n",
      "Converted DG_5xFAD_3mpos_F_Animal01_Trace102.CNG.swc to the following file: DG_5xFAD_3mpos_F_Animal01_Trace102_converted.cell.nml\n",
      "\n",
      "Error converting T-3.CNG.swc: Parent ID referred to before being defined. Loops might be present\n",
      "\n",
      "Converted Cell_090_MPD_8_FT_10_XYZ_Sorted-swc_N3DFix-swc_1.CNG.swc to the following file: Cell_090_MPD_8_FT_10_XYZ_Sorted_swc_N3DFix_swc_1_converted.cell.nml\n",
      "\n",
      "Converted PVN14_microglia_11.CNG.swc to the following file: PVN14_microglia_11_converted.cell.nml\n",
      "\n",
      "Converted 161019_12_1.CNG.swc to the following file: _161019_12_1_converted.cell.nml\n",
      "\n",
      "Converted CSR2_water-4-SNT_Data-exported-016.CNG.swc to the following file: CSR2_water_4_SNT_Data_exported_016_converted.cell.nml\n",
      "\n",
      "Converted CTR7_water-2-SNT_Data-exported-005.CNG.swc to the following file: CTR7_water_2_SNT_Data_exported_005_converted.cell.nml\n",
      "\n",
      "Converted 1-1-1_6.CNG.swc to the following file: _1_1_1_6_converted.cell.nml\n",
      "\n",
      "Converted Gad1-F-200355.CNG.swc to the following file: Gad1_F_200355_converted.cell.nml\n",
      "\n",
      "Converted VGlut-F-300031.CNG.swc to the following file: VGlut_F_300031_converted.cell.nml\n",
      "\n",
      "Converted VGlut-F-400056.CNG.swc to the following file: VGlut_F_400056_converted.cell.nml\n",
      "\n",
      "Converted VGlut-F-500070.CNG.swc to the following file: VGlut_F_500070_converted.cell.nml\n",
      "\n",
      "Converted 446263.CNG.swc to the following file: _446263_converted.cell.nml\n",
      "\n",
      "Converted 1626_S5_L2-000.CNG.swc to the following file: _1626_S5_L2_000_converted.cell.nml\n",
      "\n",
      "Converted 20190417-6B-3_P11_2.CNG.swc to the following file: _20190417_6B_3_P11_2_converted.cell.nml\n",
      "\n",
      "Converted J26_WTIV_n42_CA1_basal_cel1.CNG.swc to the following file: J26_WTIV_n42_CA1_basal_cel1_converted.cell.nml\n",
      "\n",
      "Converted V2KO_19.CNG.swc to the following file: V2KO_19_converted.cell.nml\n",
      "\n",
      "Converted skel_20073_sorted.CNG.swc to the following file: skel_20073_sorted_converted.cell.nml\n",
      "\n",
      "Converted RatS1-6-59.CNG.swc to the following file: RatS1_6_59_converted.cell.nml\n",
      "\n",
      "Converted 1-CTR_2w_Female_HIP_10.CNG.swc to the following file: _1_CTR_2w_Female_HIP_10_converted.cell.nml\n",
      "\n",
      "Converted 6-STRESS_male_Nac_1.CNG.swc to the following file: _6_STRESS_male_Nac_1_converted.cell.nml\n",
      "\n",
      "Converted Igbpf5-7866-03-F_1.CNG.swc to the following file: Igbpf5_7866_03_F_1_converted.cell.nml\n",
      "\n",
      "Converted Culture-72-3.CNG.swc to the following file: Culture_72_3_converted.cell.nml\n",
      "\n",
      "Converted BAS4-2.CNG.swc to the following file: BAS4_2_converted.cell.nml\n",
      "\n",
      "Converted 2017-3-12_525_nrx1_day3_2.CNG.swc to the following file: _2017_3_12_525_nrx1_day3_2_converted.cell.nml\n",
      "\n",
      "Converted Neuron_Hust_16.CNG.swc to the following file: Neuron_Hust_16_converted.cell.nml\n",
      "\n",
      "Converted 196-4-13nj.CNG.swc to the following file: _196_4_13nj_converted.cell.nml\n",
      "\n",
      "Converted 7B-09-traced-10.CNG.swc to the following file: _7B_09_traced_10_converted.cell.nml\n",
      "\n",
      "Converted B4-CA1-L-B63x1zCell2ACR.CNG.swc to the following file: B4_CA1_L_B63x1zCell2ACR_converted.cell.nml\n",
      "\n",
      "Converted Tracetest_N360_circle_Map2Tau2_72_semi-auto_44.CNG.swc to the following file: Tracetest_N360_circle_Map2Tau2_72_semi_auto_44_converted.cell.nml\n",
      "\n",
      "Converted C5---Adult-WT-Con.CNG.swc to the following file: C5___Adult_WT_Con_converted.cell.nml\n",
      "\n",
      "Converted 210708-ipsi-03_38.CNG.swc to the following file: _210708_ipsi_03_38_converted.cell.nml\n",
      "\n",
      "Converted AA1544.CNG.swc to the following file: AA1544_converted.cell.nml\n",
      "\n",
      "Converted 1_tracing_10X_Neuro-2a_2-day-2_30.CNG.swc to the following file: _1_tracing_10X_Neuro_2a_2_day_2_30_converted.cell.nml\n",
      "\n",
      "Converted CA1-cell-3_3.CNG.swc to the following file: CA1_cell_3_3_converted.cell.nml\n",
      "\n",
      "Converted 218_1.CNG.swc to the following file: _218_1_converted.cell.nml\n",
      "\n",
      "Converted farsight3004.CNG.swc to the following file: farsight3004_converted.cell.nml\n",
      "\n",
      "Converted 16149113.CNG.swc to the following file: _16149113_converted.cell.nml\n",
      "\n",
      "Converted E4F-97_2_A.CNG.swc to the following file: E4F_97_2_A_converted.cell.nml\n",
      "\n",
      "Converted TE3F-78_1_D.CNG.swc to the following file: TE3F_78_1_D_converted.cell.nml\n",
      "\n",
      "Converted CB_5xFAD_6mpos_M_Animal01_Trace013.CNG.swc to the following file: CB_5xFAD_6mpos_M_Animal01_Trace013_converted.cell.nml\n",
      "\n",
      "Converted CB_Adulthood_Control_M_Animal02_Trace019.CNG.swc to the following file: CB_Adulthood_Control_M_Animal02_Trace019_converted.cell.nml\n",
      "\n",
      "Converted FC_CKp25_6w_F_Animal04_Trace159.CNG.swc to the following file: FC_CKp25_6w_F_Animal04_Trace159_converted.cell.nml\n",
      "\n",
      "Converted FC_Development_P15_M_Animal02_Trace024.CNG.swc to the following file: FC_Development_P15_M_Animal02_Trace024_converted.cell.nml\n",
      "\n",
      "Converted S1_Adulthood_Control_F_Animal10_Trace034.CNG.swc to the following file: S1_Adulthood_Control_F_Animal10_Trace034_converted.cell.nml\n",
      "\n",
      "Converted S1_Recovery_2w_M_Animal02_Trace014.CNG.swc to the following file: S1_Recovery_2w_M_Animal02_Trace014_converted.cell.nml\n",
      "\n",
      "Converted 3929-P6.CNG.swc to the following file: _3929_P6_converted.cell.nml\n",
      "\n",
      "Converted B4_slide4_1.CNG.swc to the following file: B4_slide4_1_converted.cell.nml\n",
      "\n",
      "Converted 21A_1a.CNG.swc to the following file: _21A_1a_converted.cell.nml\n",
      "\n",
      "Converted ECL180_GrCellNr8_OML_IML.CNG.swc to the following file: ECL180_GrCellNr8_OML_IML_converted.cell.nml\n",
      "\n",
      "Converted TRN-4-CER-488-IBA1-594-2_1.CNG.swc to the following file: TRN_4_CER_488_IBA1_594_2_1_converted.cell.nml\n",
      "\n",
      "Converted 20121025cell05_1_a.CNG.swc to the following file: _20121025cell05_1_a_converted.cell.nml\n",
      "\n",
      "Error converting T-3.CNG.swc: More than one segment without parent (root segment) detected\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_swc = 'swc_no_api'\n",
    "path_nml = 'nml_no_api'\n",
    "print_errors = False\n",
    "\n",
    "convert_directory(path_swc, path_nml, print_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neuromorpho API**\n",
    "\n",
    "The code below is used to access the API of neuromorpho.org, which contains a large database of SWC files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "from neuromorpho_api import requestor as requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_swc_file(neuron_id):\n",
    "    '''\n",
    "    This function fetches the information about the specified neuron id and fetches the corresponding SWC file using the generated url.\n",
    "\n",
    "    Input: neuron_id: id of neuron on neuromorpho.org (int)\n",
    "\n",
    "    Returns: - SWC file contents (bytes)\n",
    "             - swc_name: name of swc file (str)\n",
    "    '''\n",
    "\n",
    "    endpoint = \"https://neuromorpho.org/api/\"\n",
    "    start = time.time()\n",
    "    response = requests.get(endpoint + f\"neuron/id/{neuron_id}\")\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise(\"Failed to fetch SWC file:\", response.text)\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    # Construct and fetch the SWC URL\n",
    "    swc_url = f\"https://neuromorpho.org/dableFiles/{data['archive'].lower()}/CNG%20version/{data['neuron_name']}.CNG.swc\"\n",
    "    swc_name = data['neuron_name']\n",
    "\n",
    "    if time.time() - start < 1/3:\n",
    "        time.sleep(1/3 - (time.time() - start))\n",
    "        \n",
    "    swc_response = requests.get(swc_url)\n",
    "    \n",
    "    if swc_response.status_code != 200:\n",
    "        raise(\"Failed to fetch SWC file:\", swc_response.text)\n",
    "    \n",
    "    time.sleep(1/3)\n",
    "\n",
    "    return swc_response.content, swc_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_swc_file(neuron_id, output_dir=''):\n",
    "    '''\n",
    "    This function writes the SWC contents to a new SWC file in an optionally specified output directory.\n",
    "\n",
    "    Input: - neuron_id: id of neuron on neuromorpho.org (int)\n",
    "           - output_dir (optional):  directory in which the SWC file will be saved (str)\n",
    "    \n",
    "    Returns: name of the newly created neuroml file (str)\n",
    "    '''\n",
    "\n",
    "    swc_content, swc_name = fetch_swc_file(neuron_id)\n",
    "    \n",
    "    if swc_content:\n",
    "        if output_dir:\n",
    "            with open(f\"{output_dir}/{swc_name}.swc\", \"wb\") as f:\n",
    "                f.write(swc_content)\n",
    "\n",
    "            return f\"{output_dir}/{swc_name}.swc\"\n",
    "        \n",
    "        else:\n",
    "            with open(f\"{swc_name}.swc\", \"wb\") as f:\n",
    "                f.write(swc_content)\n",
    "                \n",
    "            return f\"{swc_name}.swc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting files from API**\n",
    "\n",
    "In the second cell below, you can specify what range of cells you want to fetch from the API, as well as the output directories in which the SWC and NML files will be stored. Additionally, print_errors determines if the error dictionary is printed for every cell. \n",
    "\n",
    "A summary is printed, which is a dictionary containing the amount of (un)successful conversions and the amount of times certain errors occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_api(range_api, output_dir_swc, output_dir_nml, print_errors):\n",
    "    summary = {}\n",
    "    summary['Successful conversions'] = 0\n",
    "    summary['Unsuccessful conversions'] = 0\n",
    "    summary['Errors'] = {}\n",
    "    summary['Errors']['Unsuccessful fetch'] = 0\n",
    "\n",
    "    for neuron_id in range(*range_api):\n",
    "        try:\n",
    "            path = create_swc_file(neuron_id, output_dir=output_dir_swc)\n",
    "            swc_file = os.path.basename(path)\n",
    "\n",
    "            try:\n",
    "                nml_file, errors = construct_nml(path, output_dir=output_dir_nml)\n",
    "                summary['Successful conversions'] += 1\n",
    "                print(f'Converted {swc_file} to the following file: {nml_file}\\n')\n",
    "            except Exception as e:\n",
    "                errors = e.errors\n",
    "                summary['Unsuccessful conversions'] += 1\n",
    "                print(f'Error converting {swc_file}: {e}\\n')\n",
    "\n",
    "            if print_errors and errors:\n",
    "                print(json.dumps(errors, indent=2, separators=(',', ': ')))\n",
    "\n",
    "            for error in errors:\n",
    "                if error not in summary['Errors']:\n",
    "                    summary['Errors'][error] = 1\n",
    "                else:\n",
    "                    summary['Errors'][error] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            summary['Errors']['Unsuccessful fetch'] += 1\n",
    "            print(f\"Unsuccessful fetch for neuron {neuron_id}\")\n",
    "\n",
    "    pprint.pprint(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_api = (1, 2)\n",
    "output_dir_swc = 'swc_api'\n",
    "output_dir_nml = 'nml_api'\n",
    "print_errors = False\n",
    "\n",
    "convert_api(range_api, output_dir_swc, output_dir_nml, print_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
